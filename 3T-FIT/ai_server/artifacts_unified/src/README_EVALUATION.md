# Model Evaluation Guide

H∆∞·ªõng d·∫´n ƒë√°nh gi√° m√¥ h√¨nh AI cho h·ªá th·ªëng g·ª£i √Ω b√†i t·∫≠p v√† d·ª± ƒëo√°n c∆∞·ªùng ƒë·ªô t·∫≠p luy·ªán.

## üìã T·ªïng quan

C√≥ 2 lo·∫°i model c·∫ßn ƒë√°nh gi√°:

1. **Exercise Recommendation Model** - Model g·ª£i √Ω b√†i t·∫≠p v·ªõi exercise embeddings
2. **Multi-Task Learning (MTL) Model** - Model ƒëa nhi·ªám v·ª• (classification + regression)

## üéØ C√°c ch·ªâ s·ªë ƒë√°nh gi√° (Metrics)

### Classification Task (G·ª£i √Ω b√†i t·∫≠p)

| Metric          | √ù nghƒ©a                                         | Target | Excellent |
| --------------- | ----------------------------------------------- | ------ | --------- |
| **Precision@5** | T·ª∑ l·ªá b√†i t·∫≠p ƒë∆∞·ª£c g·ª£i √Ω ƒë√∫ng trong Top 5       | ‚â• 0.70 | ‚â• 0.85    |
| **Recall@5**    | T·ª∑ l·ªá b√†i t·∫≠p ph√π h·ª£p ƒë∆∞·ª£c t√¨m th·∫•y trong Top 5 | ‚â• 0.60 | ‚â• 0.75    |
| **F1-Score@5**  | Trung b√¨nh ƒëi·ªÅu h√≤a c·ªßa Precision v√† Recall     | ‚â• 0.65 | ‚â• 0.80    |

### Regression Task (D·ª± ƒëo√°n c∆∞·ªùng ƒë·ªô)

| Metric   | Parameter         | Target             | Excellent |
| -------- | ----------------- | ------------------ | --------- |
| **MAE**  | Sets (s·ªë hi·ªáp)    | ‚â§ 0.5              | ‚â§ 0.3     |
| **MAE**  | Reps (s·ªë l·∫ßn l·∫∑p) | ‚â§ 2.0              | ‚â§ 1.0     |
| **MAE**  | Load (kg)         | ‚â§ 5.0              | ‚â§ 3.0     |
| **RMSE** | T·∫•t c·∫£ parameters | C√†ng th·∫•p c√†ng t·ªët | -         |
| **R¬≤**   | T·∫•t c·∫£ parameters | ‚â• 0.70             | ‚â• 0.85    |

## üöÄ C√°ch s·ª≠ d·ª•ng

### 1. ƒê√°nh gi√° Exercise Recommendation Model

```bash
cd ai_server/artifacts_unified/src

# S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh
python evaluate_exercise_model.py

# Ho·∫∑c ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n c·ª• th·ªÉ
python evaluate_exercise_model.py \
    --model_path ../artifacts_exercise_rec/best_model.pt \
    --test_data ../../../Data/data/merged_omni_health_dataset.xlsx \
    --artifacts ../artifacts_exercise_rec
```

**Output m·∫´u:**

```
================================================================================
EXERCISE RECOMMENDATION MODEL EVALUATION
================================================================================

[1/6] Loading metadata from: ../artifacts_exercise_rec/metadata.json
  ‚úì Model trained on: 2025-11-20T12:30:45
  ‚úì Number of exercises: 66

[2/6] Loaded preprocessor from: ../artifacts_exercise_rec/preprocessor.joblib

[3/6] Loading test data from: ../../../Data/data/merged_omni_health_dataset.xlsx
  ‚úì Loaded 204 test samples

[4/6] Loading model from: ../artifacts_exercise_rec/best_model.pt
  ‚úì Model loaded (epoch 85)

[5/6] Running evaluation...

[6/6] Evaluation Results:
================================================================================

üìä CLASSIFICATION METRICS (Exercise Recommendation)
--------------------------------------------------------------------------------
  Precision@5:  0.7823
  Recall@5:     0.6541
  F1-Score@5:   0.7123
  Precision@10: 0.7234
  Recall@10:    0.7012
  F1-Score@10:  0.7121

üìà REGRESSION METRICS (Intensity Parameters)
--------------------------------------------------------------------------------
Parameter       MAE          RMSE         R¬≤           Samples
--------------------------------------------------------------------------------
sets            0.3245       0.4521       0.8234       195
reps            1.2341       1.8923       0.7823       195
kg              2.8934       4.1234       0.8512       180
km              0.4523       0.6234       0.7234       24
min             3.2341       5.1234       0.7923       204
minRest         0.2341       0.3456       0.6234       150
avgHR           5.2341       8.1234       0.7512       180
peakHR          6.3412       9.2341       0.7234       180

‚úÖ Evaluation completed!
Results saved to: ../artifacts_exercise_rec/evaluation_results.json
================================================================================
```

### 2. ƒê√°nh gi√° MTL Model

```bash
cd ai_server/artifacts_unified/src

# S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh
python evaluate_mtl_model.py

# Ho·∫∑c ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n c·ª• th·ªÉ
python evaluate_mtl_model.py \
    --model_path ../artifacts_omni_mlbce/best.pt \
    --test_data ../data/merged_omni_health_dataset.xlsx \
    --artifacts ../artifacts_omni_mlbce
```

**Output m·∫´u:**

```
================================================================================
MULTI-TASK LEARNING (MTL) MODEL EVALUATION
================================================================================

[1/6] Loading metadata from: ../artifacts_omni_mlbce/meta.json
  ‚úì Number of exercises: 200
  ‚úì Input dimension: 15

[2/6] Loaded preprocessor from: ../artifacts_omni_mlbce/preprocessor.joblib

[3/6] Loading test data from: ../data/merged_omni_health_dataset.xlsx
  ‚úì Loaded 204 test samples

[4/6] Loading model from: ../artifacts_omni_mlbce/best.pt
  ‚úì Model loaded successfully

[5/6] Running evaluation...

[6/6] Evaluation Results:
================================================================================

üìä CLASSIFICATION METRICS (Exercise Recommendation)
--------------------------------------------------------------------------------
  Precision@5:  0.8123
  Recall@5:     0.6823
  F1-Score@5:   0.7412
  Precision@10: 0.7534
  Recall@10:    0.7234
  F1-Score@10:  0.7381

üìà REGRESSION METRICS (Intensity Parameters)
--------------------------------------------------------------------------------
Parameter       MAE          RMSE         R¬≤           Samples
--------------------------------------------------------------------------------
sets            0.2834       0.3921       0.8634       195
reps            1.0234       1.5234       0.8234       195
load_kg         2.3412       3.4521       0.8823       180

üéØ PERFORMANCE ASSESSMENT
--------------------------------------------------------------------------------
  Classification P@5: 0.8123 - ‚úÖ Good
  Classification R@5: 0.6823 - ‚úÖ Good
  Regression Sets MAE: 0.2834 - üåü Excellent
  Regression Reps MAE: 1.0234 - üåü Excellent
  Regression Load MAE: 2.3412 kg - üåü Excellent

‚úÖ Evaluation completed!
Results saved to: ../artifacts_omni_mlbce/evaluation_results.json
================================================================================
```

## üìä K·∫øt qu·∫£ ƒë·∫ßu ra

Sau khi ch·∫°y evaluation, file `evaluation_results.json` s·∫Ω ƒë∆∞·ª£c t·∫°o ra v·ªõi c·∫•u tr√∫c:

```json
{
  "classification": {
    "precision@5": 0.8123,
    "recall@5": 0.6823,
    "f1@5": 0.7412,
    "precision@10": 0.7534,
    "recall@10": 0.7234,
    "f1@10": 0.7381
  },
  "regression": {
    "sets": {
      "mae": 0.2834,
      "rmse": 0.3921,
      "r2": 0.8634,
      "n_samples": 195
    },
    "reps": {
      "mae": 1.0234,
      "rmse": 1.5234,
      "r2": 0.8234,
      "n_samples": 195
    },
    "load_kg": {
      "mae": 2.3412,
      "rmse": 3.4521,
      "r2": 0.8823,
      "n_samples": 180
    }
  },
  "test_samples": 204,
  "model_path": "../artifacts_omni_mlbce/best.pt",
  "test_data_path": "../data/merged_omni_health_dataset.xlsx"
}
```

## üîç Ph√¢n t√≠ch k·∫øt qu·∫£

### Gi·∫£i th√≠ch c√°c metrics

#### **Precision@K**

- ƒêo l∆∞·ªùng ƒë·ªô ch√≠nh x√°c c·ªßa c√°c g·ª£i √Ω
- C√¥ng th·ª©c: `TP / (TP + FP)`
- V√≠ d·ª•: Precision@5 = 0.80 nghƒ©a l√† 80% trong 5 b√†i t·∫≠p ƒë∆∞·ª£c g·ª£i √Ω l√† ph√π h·ª£p

#### **Recall@K**

- ƒêo l∆∞·ªùng ƒë·ªô bao ph·ªß c·ªßa c√°c g·ª£i √Ω
- C√¥ng th·ª©c: `TP / (TP + FN)`
- V√≠ d·ª•: Recall@5 = 0.70 nghƒ©a l√† 70% b√†i t·∫≠p ph√π h·ª£p ƒë∆∞·ª£c t√¨m th·∫•y trong Top 5

#### **F1-Score@K**

- Trung b√¨nh ƒëi·ªÅu h√≤a c·ªßa Precision v√† Recall
- C√¥ng th·ª©c: `2 * (P * R) / (P + R)`
- C√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c v√† ƒë·ªô bao ph·ªß

#### **MAE (Mean Absolute Error)**

- Sai s·ªë tuy·ªát ƒë·ªëi trung b√¨nh
- C√¥ng th·ª©c: `Œ£|y_pred - y_true| / n`
- V√≠ d·ª•: MAE = 1.5 reps nghƒ©a l√† trung b√¨nh sai l·ªách 1.5 l·∫ßn l·∫∑p

#### **RMSE (Root Mean Square Error)**

- CƒÉn b·∫≠c hai c·ªßa sai s·ªë b√¨nh ph∆∞∆°ng trung b√¨nh
- C√¥ng th·ª©c: `‚àö(Œ£(y_pred - y_true)¬≤ / n)`
- Ph·∫°t n·∫∑ng h∆°n c√°c sai s·ªë l·ªõn

#### **R¬≤ Score**

- H·ªá s·ªë x√°c ƒë·ªãnh - ƒëo m·ª©c ƒë·ªô ph√π h·ª£p c·ªßa m√¥ h√¨nh
- Gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1 (1 l√† ho√†n h·∫£o)
- R¬≤ = 0.85 nghƒ©a l√† m√¥ h√¨nh gi·∫£i th√≠ch ƒë∆∞·ª£c 85% ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu

### Khi n√†o c·∫ßn c·∫£i thi·ªán model?

‚ö†Ô∏è **C·∫ßn c·∫£i thi·ªán n·∫øu:**

- Precision@5 < 0.70
- Recall@5 < 0.60
- MAE (Sets) > 0.5
- MAE (Reps) > 2.0
- MAE (Load) > 5.0 kg
- R¬≤ < 0.70

‚úÖ **Model t·ªët n·∫øu:**

- 0.70 ‚â§ Precision@5 < 0.85
- 0.60 ‚â§ Recall@5 < 0.75
- 0.3 < MAE (Sets) ‚â§ 0.5
- 1.0 < MAE (Reps) ‚â§ 2.0
- 3.0 < MAE (Load) ‚â§ 5.0 kg
- 0.70 ‚â§ R¬≤ < 0.85

üåü **Model xu·∫•t s·∫Øc n·∫øu:**

- Precision@5 ‚â• 0.85
- Recall@5 ‚â• 0.75
- MAE (Sets) ‚â§ 0.3
- MAE (Reps) ‚â§ 1.0
- MAE (Load) ‚â§ 3.0 kg
- R¬≤ ‚â• 0.85

## üõ†Ô∏è Troubleshooting

### L·ªói: "File not found"

```bash
# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n
ls ../artifacts_exercise_rec/best_model.pt
ls ../../../Data/data/merged_omni_health_dataset.xlsx
```

### L·ªói: "Module not found"

```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng th∆∞ m·ª•c
cd ai_server/artifacts_unified/src

# Ho·∫∑c th√™m PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### L·ªói: "CUDA out of memory"

```python
# Trong script, thay ƒë·ªïi:
device = torch.device('cpu')  # Thay v√¨ 'cuda'
```

## üìö Tham kh·∫£o

- [Workflow Training](../../workflow.md) - Quy tr√¨nh training model
- [README Exercise Recommendation](README_EXERCISE_REC.md) - Chi ti·∫øt v·ªÅ Exercise Recommendation Model
- [Scikit-learn Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) - T√†i li·ªáu v·ªÅ metrics
